{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summarization using NLTK\n",
    "\n",
    "**AIM:** Design a script to produce a summary from scrapped tweets.  \n",
    "**Reference:** [Text summarization with NLTK in Python.](https://stackabuse.com/text-summarization-with-nltk-in-python/)  \n",
    "\n",
    "\n",
    "STEPS:  \n",
    "- define text preprocessing to be done and do the text preprocessing\n",
    "- combine cleaned tweets into one document\n",
    "- extract a summary of the information from the large document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "##\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "import heapq\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1310865450960642048</td>\n",
       "      <td>‚ÄúComing together is a beginning; keeping toget...</td>\n",
       "      <td>2020-09-29 08:54:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1310864804010225665</td>\n",
       "      <td>Today is Empowerment day for Hustlers.\\n\\nEver...</td>\n",
       "      <td>2020-09-29 08:51:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1310864208859402240</td>\n",
       "      <td>MERCY is all i crave for right nw. Oh Lord...s...</td>\n",
       "      <td>2020-09-29 08:49:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1310863174296453120</td>\n",
       "      <td>we all know what this hustler movment is about...</td>\n",
       "      <td>2020-09-29 08:45:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1310862095567773696</td>\n",
       "      <td>Self taught baker. @Stephjoybakery IG and FB. ...</td>\n",
       "      <td>2020-09-29 08:40:52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id  \\\n",
       "0           0  1310865450960642048   \n",
       "1           1  1310864804010225665   \n",
       "2           2  1310864208859402240   \n",
       "3           3  1310863174296453120   \n",
       "4           4  1310862095567773696   \n",
       "\n",
       "                                                text           created_at  \\\n",
       "0  ‚ÄúComing together is a beginning; keeping toget...  2020-09-29 08:54:12   \n",
       "1  Today is Empowerment day for Hustlers.\\n\\nEver...  2020-09-29 08:51:38   \n",
       "2  MERCY is all i crave for right nw. Oh Lord...s...  2020-09-29 08:49:16   \n",
       "3  we all know what this hustler movment is about...  2020-09-29 08:45:10   \n",
       "4  Self taught baker. @Stephjoybakery IG and FB. ...  2020-09-29 08:40:52   \n",
       "\n",
       "   likes  retweet_count  \n",
       "0      0              0  \n",
       "1      1              0  \n",
       "2      1              0  \n",
       "3      0              0  \n",
       "4      0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in a csv file\n",
    "##\n",
    "df = pd.read_csv(\"#RespectMyHustle.csv\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample df to 30 rows\n",
    "This will ensure preprocessing of dataframes take equal or approximately equal time iregardless of dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 30:\n",
    "    df = df.sample(30, random_state=30).reset_index(drop=True)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúComing together is a beginning; keeping together is progress; working together is success.‚Äù\n",
      "\n",
      "#TuesdayThoughts \n",
      "#RespectMyHustle \n",
      "\n",
      "Today is Empowerment day for Hustlers.\n",
      "\n",
      "Every Hustle matters.\n",
      "\n",
      "#RespectMyHustle \n",
      "\n",
      "#HustlerNation \n",
      "\n",
      "MERCY is all i crave for right nw. Oh Lord...send me an HELPER asapüôèüèº\n",
      "#lagos #RespectMyHustle #Alert \n",
      "\n",
      "we all know what this hustler movment is about.Its only one mans political ambitions,real kenyans know were on our own. #respectmyhustle \n",
      "\n",
      "Self taught baker. @Stephjoybakery IG and FB. #RespectMyHustle \n",
      "\n",
      "#respectmyhustle\n",
      "\n",
      "I do online writing \n",
      "\n",
      "This is a country of few millionaires and tens of millions Hustlers.\n",
      "\n",
      "Thank u DP Ruto for recognizing Hustlers.\n",
      "\n",
      "#RespectMyHustle \n",
      "\n",
      "The dynasties can keep dictionary meaning of the word hustler to themselves, as a farmer am an hustler #respectmyhustle \n",
      "\n",
      "@WilliamsRuto We appriciate your concern with Kenyans, with love from Tanzania #RespectMyHustle #FUTUREPRESIDENT \n",
      "\n",
      "@Future_maina Very cute. How much is the dog?#RespectMyHustle \n",
      "\n",
      "My babe came to my house with another boy and called me bestie üò≠üò≠\n",
      "What should I do now?\n",
      "#RespectMyHustle \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a closer look at the texts\n",
    "##\n",
    "for tweet in df.text:\n",
    "    print(tweet, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing steps\n",
    "- remove links\n",
    "- remove hashtags\n",
    "- remove special characters (preserving fullstops since they mark end of sentence and we're doing summarization based off of sentence weights, also preserve single quotes)\n",
    "- remove numbers\n",
    "- remove emojis and emoticons\n",
    "- correct spelling\n",
    "- stripping the text\n",
    "- put a fullstop at the end of each preprocessed tweet if there is not one\n",
    "- make the first letter of preprocessed tweets a capital letter if it isn't the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do the preprocessing\n",
    "##\n",
    "\n",
    "punctuation = '!\"#$%&\\()*+,-/:;<=>?@[\\\\]^_`{|}~‚Ä¶' # removed fullstop and single quote\n",
    "emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "def text_process(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', repl=r'', string=text)\n",
    "    text = text.split()\n",
    "    text = ' '.join([word for word in text if not word.startswith(\"#\")])\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = re.sub(emoj, '', text)\n",
    "    text = str(TextBlob(text).correct())\n",
    "    text = text.strip()\n",
    "    if not text.endswith(\".\"):\n",
    "        text = text + \".\"\n",
    "    if not text[0].isupper():\n",
    "        text = text[0].upper() + text[1:]\n",
    "    return text\n",
    "\n",
    "# text processing function preserving digits\n",
    "def text_processdig(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', repl=r'', string=text)\n",
    "    text = text.split()\n",
    "    text = ' '.join([word for word in text if not word.startswith(\"#\")])\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    text = re.sub(emoj, '', text)\n",
    "    text = str(TextBlob(text).correct())\n",
    "    text = text.strip()\n",
    "    if not text.endswith(\".\"):\n",
    "        text = text + \".\"\n",
    "    if not text[0].isupper():\n",
    "        text = text[0].upper() + text[1:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  The story about closing of schools has made school girls know that love is not given but paid for.\n",
      " #Covid19Millionaires\n",
      "\n",
      "Preprocessed text:  The story about closing of schools has made school girls know that love is not given but paid for.\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(\"Original text: \", df.text[0])\n",
    "print(\"\\nPreprocessed text: \", text_process(df.text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing a document of preprocessed texts joined together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Designing preprocessed document:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:16<00:00,  1.84it/s]\n",
      "Designing document preserving numbers:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:17<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_without_numbers = \"\"\n",
    "\n",
    "for tweet in tqdm(df.text, desc=\"Designing preprocessed document:\"):\n",
    "    tweet = text_process(tweet)\n",
    "    doc_without_numbers += tweet\n",
    "    \n",
    "doc_with_numbers = \"\"\n",
    "\n",
    "for tweet in tqdm(df.text, desc=\"Designing document preserving numbers:\"):\n",
    "    tweet = text_processdig(tweet)\n",
    "    doc_with_numbers += tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert document to recognizable sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = nltk.sent_tokenize(doc_with_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The story about closing of schools has made school girls know that love is not given but paid for.NMSKenya Meeting for the how will I benefit from it by the way.ItsNyambane same way fools like you are dancing with who stole from the sick.',\n",
       " 'staff.Were amongst those who attended the summit.',\n",
       " \"Shameless to sit and ridicule fellow Kenyans with face speeches.He are Still Waiting for to be Brought to Took Am AFRAID He might wait till we get to the GRAVE.ARE ALREADY LEARNING THAT MORE MONEY MORE PROBLEMS.OmbetaC You wanted him to join hands with after feasting covid19 funds He did well of.Welcome to sonya where to be poor is a crime.MarkDienya RailaOdinga He is not part of the his.An one get a good job in sonya nowadays without experience.... An't you train me and make me experienced.CORRUPTION of NEW NORMAL of KENYA of SHOULD LEARN of COPE WITH of JKNjenga.You heard the message loud and clear no money was lost.\",\n",
       " 'Real with it...TheStarKenya StateHouseKenya MOHKenya But You Stole Money Related To Covid19 of EXPECTED.StateHouseKenya MOHKenya KenyaGovernors Conference on making more Sonya needs prayers and redemption.In this country a self published book does not stand a change of a shelf slot Demyan book stores are hilarious.RobertAlai Search not found.',\n",
       " \"Did you mean conference.It is high time the pack and go He are tired Sonya is tired Poverty is rising.Hurt heads to France to borrow more for.You look at of Magoha's confusion and you wonder what's the essence of that 100page of.USAmbKenya It least u now know our got is full of.All national thieves are at kick....\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing the first 5 sentences\n",
    "##\n",
    "sentence_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find weighted frequency of occurence of each word(using preprocessed document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in nltk.word_tokenize(doc_without_numbers):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "            \n",
    "# to find the weighted frequency, we can simply divide the number of occurances of\n",
    "# all the words by the frequency of the most occurring word\n",
    "\n",
    "maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sentence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) > 3 & len(sent.split(' ')) < 20:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting summary from sentences with higher score than others\n",
    "Taking care of shorter and extremely longer summaries  \n",
    "- summaries below 1500 characters  \n",
    "- summaries over  2500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "summary_sentences = heapq.nlargest(n, sentence_scores, key=sentence_scores.get)\n",
    "summary = ' '.join(summary_sentences)\n",
    "\n",
    "if len(summary) < 1500 and len(' '.join(df.text)) > 1500:\n",
    "    while len(summary) < 2500:\n",
    "        if n+3 < len(sentence_list):\n",
    "            n = n+3\n",
    "        summary_sentences = heapq.nlargest(n, sentence_scores, key=sentence_scores.get)\n",
    "        \n",
    "summary = ' '.join(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shameless to sit and ridicule fellow Kenyans with face speeches.He are Still Waiting for to be Brought to Took Am AFRAID He might wait till we get to the GRAVE.ARE ALREADY LEARNING THAT MORE MONEY MORE PROBLEMS.OmbetaC You wanted him to join hands with after feasting covid19 funds He did well of.Welcome to sonya where to be poor is a crime.MarkDienya RailaOdinga He is not part of the his.An one get a good job in sonya nowadays without experience.... An't you train me and make me experienced.CORRUPTION of NEW NORMAL of KENYA of SHOULD LEARN of COPE WITH of JKNjenga.You heard the message loud and clear no money was lost. Did you mean conference.It is high time the pack and go He are tired Sonya is tired Poverty is rising.Hurt heads to France to borrow more for.You look at of Magoha's confusion and you wonder what's the essence of that 100page of.USAmbKenya It least u now know our got is full of.All national thieves are at kick.... Real with it...TheStarKenya StateHouseKenya MOHKenya But You Stole Money Related To Covid19 of EXPECTED.StateHouseKenya MOHKenya KenyaGovernors Conference on making more Sonya needs prayers and redemption.In this country a self published book does not stand a change of a shelf slot Demyan book stores are hilarious.RobertAlai Search not found. And no man can respect himself when he does not repay honest debts.Wekesir Lazima alice white oh... Of he reopened it would be obvious he's sanitizing the.AnneMbugua16 StateHouseKenya were the beneficiaries.ItsNyambane Are you justifying. The story about closing of schools has made school girls know that love is not given but paid for.NMSKenya Meeting for the how will I benefit from it by the way.ItsNyambane same way fools like you are dancing with who stole from the sick.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting errors in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of matches: 2\n",
      "A sentence with an error in the Hitchhiker‚Äôs Guide to the Galaxy\n"
     ]
    }
   ],
   "source": [
    "# example of how the tool makes correction\n",
    "##\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "text = 'A sentence with a error in the Hitchhiker‚Äôs Guide tot he Galaxy'\n",
    "matches = tool.check(text)\n",
    "\n",
    "print(f\"Length of matches: {len(matches)}\")\n",
    "\n",
    "text = tool.correct(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying to our summary text\n",
    "##\n",
    "matches = tool.check(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = tool.correct(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shameless to sit and ridicule fellow Kenyans with face speeches. He is Still Waiting for to be Brought to Took Am AFRAID He might wait till we get to the GRAVE.ARE ALREADY LEARNING THAT MORE MONEY MORE PROBLEMS. OmbetaC You wanted him to join hands with after feasting COVID-19 funds He did well of. Welcome to Sonya where to be poor is a crime. MarkDienya Railroading He is not part of the. An one get a good job in Sonya nowadays without experience.... An't you train me and make me experienced.CORRUPTION of NEW NORMAL of KENYA of SHOULD LEARN of COPE WITH of JKNjenga. You heard the message loud and clear no money was lost. Did you mean conference? It is high time the pack and go He is tired Sonya is tired Poverty is rising. Hurt heads to France to borrow more for. You look at of Martha's confusion and you wonder what's the essence of that 100page of.USAmbKenya It least u now know our got is full of. All national thieves are at kick.... Real with it... TheStarKenya StateHouse Kenya MOH Kenya But You Stole Money Related To COVID-19 of EXPECTED. StateHouseKenya MOH Kenya KenyaGovernors Conference on making more Sonya needs prayers and redemption. In this country a self-published book does not stand a change of a shelf slot Demean book stores are hilarious. RobertAlai Search not found. And no man can respect himself when he does not repay honest debts. Wekesir Lima Alice white oh... Of he reopened it would be obvious he's sanitizing the. AnneMbugua16 StateHouse Kenya were the beneficiaries. ItsNyambane Are you justifying. The story about closing of schools has made school girls know that love is not given but paid for.Kenya Meeting for how will I benefit from it by the way. ItsNyambane same way fools like you are dancing with who stole from the sick.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
